{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b072f5-0e36-416b-80d0-cd6b0a25b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a8d057-a306-419b-aaf3-1c0a08f33a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internships</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   internships  profile_score  lpa\n",
       "0            8              8    4\n",
       "1            7              9    5\n",
       "2            6             10    6\n",
       "3            5             12    7\n",
       "4            4             10    5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame (\n",
    "    [[8,8,4],[7,9,5],[6,10,6],[5,12,7],[4,10,5]],\n",
    "    columns=['internships', 'profile_score', 'lpa']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8497c161-8f4e-4a84-9b23-bf7f560f0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers will contain the size of each layer\n",
    "def initialize(layers): # initialize all the weights to 1 and bias to 0\n",
    "    parameters = {}\n",
    "\n",
    "    for l in range (1, len(layers)):\n",
    "        parameters['W'+str(l)] = np.ones((layers[l-1], layers[l]))\n",
    "        parameters['b'+str(l)] = np.zeros((layers[l], 1))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98bddaa-77ce-4e11-93ff-cf7439430611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_calc(A_prev, w, b):\n",
    "    Z = np.dot(w.T, A_prev) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2763b17f-69f1-41bc-b00f-e508d2c0f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        wl = parameters['W'+str(l)]\n",
    "        bl = parameters['b'+str(l)]\n",
    "\n",
    "        A = layer_calc(A_prev, wl, bl)\n",
    "\n",
    "    y_hat = A[0][0]\n",
    "    return y_hat, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b97242-5bd8-4623-ba8c-08d0dbfc2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(parameters, y, y_hat, A1, X): #updating the parameters\n",
    "    learning_rate = 0.001\n",
    "    parameters['W2'][0][0] = parameters['W2'][0][0] + (learning_rate * 2 * (y - y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0] = parameters['W2'][1][0] + (learning_rate * 2 * (y - y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0] = parameters['W2'][1][0] + (learning_rate * 2 * (y - y_hat))\n",
    "\n",
    "    parameters['W1'][0][0] = parameters['W1'][0][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "    parameters['W1'][0][1] = parameters['W1'][0][1] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "    parameters['b1'][0][0] = parameters['b1'][0][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0] = parameters['W1'][1][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "    parameters['W1'][1][1] = parameters['W1'][1][1] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "    parameters['b1'][1][0] = parameters['b1'][1][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d669a193-1b8c-46d3-a36f-ddf61fed1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5, Loss - 1.3600493243139717\n",
      "Epoch - 10, Loss - 1.3558815531516404\n",
      "Epoch - 15, Loss - 1.3514182280379372\n",
      "Epoch - 20, Loss - 1.3467118577834853\n",
      "Epoch - 25, Loss - 1.3418193114196404\n",
      "Epoch - 30, Loss - 1.336801511054055\n",
      "Epoch - 35, Loss - 1.3317231273566086\n",
      "Epoch - 40, Loss - 1.3266522919934747\n",
      "Epoch - 45, Loss - 1.321660340174584\n",
      "Epoch - 50, Loss - 1.3168215947312998\n",
      "Epoch - 55, Loss - 1.312213200820438\n",
      "Epoch - 60, Loss - 1.30791501744501\n",
      "Epoch - 65, Loss - 1.3040095684175483\n",
      "Epoch - 70, Loss - 1.3005820510017434\n",
      "Epoch - 75, Loss - 1.2977203949557246\n",
      "Epoch - 80, Loss - 1.295515357590462\n",
      "Epoch - 85, Loss - 1.2940606310338993\n",
      "Epoch - 90, Loss - 1.293452925119145\n",
      "Epoch - 95, Loss - 1.2937919717318809\n",
      "Epoch - 100, Loss - 1.2951803720477006\n",
      "Final Parameters:  {'W1': array([[1.05133958, 1.19375513],\n",
      "       [1.06461087, 1.2072599 ]]), 'b1': array([[0.01010137],\n",
      "       [0.0118249 ]]), 'W2': array([[0.15361836],\n",
      "       [0.14886973]]), 'b2': array([[0.14685328]])}\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize([2, 2, 1]) #network with 3 layers\n",
    "epochs = 100\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    loss = []\n",
    "\n",
    "    for j in range(df.shape[0]): #iterating over all rows in the df\n",
    "        X = df[['internships', 'profile_score']].values[j].reshape(2,1)\n",
    "        y = df[['lpa']].values[j][0]\n",
    "\n",
    "        y_hat, A1 = forward_propagation(X, parameters)\n",
    "        back_propogation(parameters, y, y_hat, A1, X)\n",
    "\n",
    "        loss.append((y-y_hat)**2) # Loss function is MSE and Activation Function is Linear\n",
    "\n",
    "    if(i%5==0):\n",
    "        print(f\"Epoch - {i}, Loss - {np.array(loss).mean()}\")\n",
    "\n",
    "print(\"Final Parameters: \", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dc07a-843f-498f-bcd0-939831c453b7",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6aec35-515f-4425-87ec-bae3404cd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f32ec0-135f-4da0-ab00-2b35c26b8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(2,)))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b689f60e-5c27-4a83-9c13-10c698f033da",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tensorflow.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70279d12-81d6-4670-9280-dafea03fe46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3fbb5d-3853-40fa-8004-ae978eba2430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.60493106,  0.41120386],\n",
       "        [ 1.1746551 , -0.807788  ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.39700377],\n",
       "        [ 1.3876363 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25cadb81-ecde-45e5-8eac-aa1e79e4f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([\n",
    "    np.array([[1,1],[1,1]]), np.array([0,0]), np.array([[1],[1]]), np.array([0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016316c4-1307-4c25-b22f-57a82b57f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 929us/step - loss: 620.8372\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 594us/step - loss: 479.7785\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 643us/step - loss: 359.9280\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 607us/step - loss: 270.0307\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 198.7092\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 674us/step - loss: 146.4005\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 665us/step - loss: 109.8160\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 630us/step - loss: 80.0367\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 542us/step - loss: 59.2666\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 591us/step - loss: 44.7520\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 655us/step - loss: 33.3604\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 663us/step - loss: 25.7454\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 19.7103\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 578us/step - loss: 15.3883\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 638us/step - loss: 11.8851\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 607us/step - loss: 9.5142\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 7.5646\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 616us/step - loss: 6.0548\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 533us/step - loss: 5.0895\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 607us/step - loss: 4.0018\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 690us/step - loss: 3.4328\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 563us/step - loss: 2.8995\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 536us/step - loss: 2.4589\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 2.0850\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 572us/step - loss: 1.7881\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 544us/step - loss: 1.6277\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 592us/step - loss: 1.4326\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 488us/step - loss: 1.3318\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 547us/step - loss: 1.1815\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 570us/step - loss: 1.1004\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 614us/step - loss: 1.0434\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 553us/step - loss: 0.9941\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.9657\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.9237\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.8961\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 539us/step - loss: 0.8779\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.8559\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 547us/step - loss: 0.8475\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.8361\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.8206\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 512us/step - loss: 0.8262\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.8098\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.8057\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.8062\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.7963\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.8022\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.7903\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 486us/step - loss: 0.7884\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.7849\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.7833\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.7836\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.7788\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.7766\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 544us/step - loss: 0.7786\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.7729\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.7765\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.7667\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.7710\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.7651\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.7614\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 528us/step - loss: 0.7586\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 562us/step - loss: 0.7583\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.7565\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.7565\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.7569\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.7513\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 470us/step - loss: 0.7478\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.7459\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.7466\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 541us/step - loss: 0.7382\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 550us/step - loss: 0.7383\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 495us/step - loss: 0.7333\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.7322\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 593us/step - loss: 0.7294\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.7249\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.7234\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 510us/step - loss: 0.7207\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 476us/step - loss: 0.7188\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 510us/step - loss: 0.7157\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.7164\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 479us/step - loss: 0.7114\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.7098\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 512us/step - loss: 0.7059\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.7035\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 550us/step - loss: 0.7025\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.6990\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.7025\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.7000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 461us/step - loss: 0.6919\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 539us/step - loss: 0.6877\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.6860\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 482us/step - loss: 0.6858\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 515us/step - loss: 0.6814\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.6771\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 508us/step - loss: 0.6833\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 472us/step - loss: 0.6722\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.6737\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 547us/step - loss: 0.6689\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 491us/step - loss: 0.6709\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 500us/step - loss: 0.6629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a14846d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df[['internships', 'profile_score']].values, df['lpa'], epochs=100, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7cd990f-d0b0-4b3d-ac6e-149550c042fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.40770516, 0.40770516],\n",
       "        [0.48700055, 0.48700055]], dtype=float32),\n",
       " array([-0.5553082, -0.5553082], dtype=float32),\n",
       " array([[0.45852244],\n",
       "        [0.45852244]], dtype=float32),\n",
       " array([-0.6782013], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
