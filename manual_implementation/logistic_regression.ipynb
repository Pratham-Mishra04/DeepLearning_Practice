{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b072f5-0e36-416b-80d0-cd6b0a25b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a8d057-a306-419b-aaf3-1c0a08f33a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internships</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   internships  profile_score  placed\n",
       "0            8              8       1\n",
       "1            7              9       1\n",
       "2            6             10       0\n",
       "3            5             12       1\n",
       "4            4             10       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame (\n",
    "    [[8,8,1],[7,9,1],[6,10,0],[5,12,1],[4,10,0]],\n",
    "    columns=['internships', 'profile_score', 'placed']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8497c161-8f4e-4a84-9b23-bf7f560f0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers will contain the size of each layer\n",
    "def initialize(layers): # initialize all the weights to 1 and bias to 0\n",
    "    parameters = {}\n",
    "\n",
    "    for l in range (1, len(layers)):\n",
    "        parameters['W'+str(l)] = np.ones((layers[l-1], layers[l]))\n",
    "        parameters['b'+str(l)] = np.zeros((layers[l], 1))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ed6382-ca77-4858-89e4-9da330d7dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "  return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98bddaa-77ce-4e11-93ff-cf7439430611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_calc(A_prev, w, b):\n",
    "    Z = np.dot(w.T, A_prev) + b\n",
    "    return sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2763b17f-69f1-41bc-b00f-e508d2c0f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        wl = parameters['W'+str(l)]\n",
    "        bl = parameters['b'+str(l)]\n",
    "\n",
    "        A = layer_calc(A_prev, wl, bl)\n",
    "\n",
    "    y_hat = A[0][0]\n",
    "    return y_hat, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b97242-5bd8-4623-ba8c-08d0dbfc2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(parameters, y, y_hat, A1, X): #updating the parameters\n",
    "    learning_rate = 0.001\n",
    "    parameters['W2'][0][0] = parameters['W2'][0][0] + (learning_rate * 2 * (y - y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0] = parameters['W2'][1][0] + (learning_rate * 2 * (y - y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0] = parameters['W2'][1][0] + (learning_rate * 2 * (y - y_hat))\n",
    "\n",
    "    parameters['W1'][0][0] = parameters['W1'][0][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "    parameters['W1'][0][1] = parameters['W1'][0][1] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "    parameters['b1'][0][0] = parameters['b1'][0][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0] = parameters['W1'][1][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "    parameters['W1'][1][1] = parameters['W1'][1][1] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "    parameters['b1'][1][0] = parameters['b1'][1][0] + (learning_rate * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d669a193-1b8c-46d3-a36f-ddf61fed1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5, Loss - 1.2332142081647435\n",
      "Epoch - 10, Loss - 1.2149030262445208\n",
      "Epoch - 15, Loss - 1.196705560263507\n",
      "Epoch - 20, Loss - 1.1772367526361058\n",
      "Epoch - 25, Loss - 1.1442117677402093\n",
      "Epoch - 30, Loss - 1.0421172345883298\n",
      "Epoch - 35, Loss - 0.9168754350956609\n",
      "Epoch - 40, Loss - 0.8739879481790787\n",
      "Epoch - 45, Loss - 0.8621971346290295\n",
      "Epoch - 50, Loss - 0.8564478930077953\n",
      "Epoch - 55, Loss - 0.8510491776724329\n",
      "Epoch - 60, Loss - 0.844256084681956\n",
      "Epoch - 65, Loss - 0.8348048431619519\n",
      "Epoch - 70, Loss - 0.8215404885788293\n",
      "Epoch - 75, Loss - 0.8042151050975681\n",
      "Epoch - 80, Loss - 0.784552002161947\n",
      "Epoch - 85, Loss - 0.7657400428580472\n",
      "Epoch - 90, Loss - 0.7502066940406115\n",
      "Epoch - 95, Loss - 0.7384792719876792\n",
      "Epoch - 100, Loss - 0.7299227352123843\n",
      "Final Parameters:  {'W1': array([[-0.0248405 , -1.29940446],\n",
      "       [-0.07276898, -1.41786549]]), 'b1': array([[-0.2276903 ],\n",
      "       [-0.23934172]]), 'W2': array([[0.76537822],\n",
      "       [0.89429536]]), 'b2': array([[0.89279351]])}\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize([2, 2, 1]) #network with 3 layers\n",
    "epochs = 100\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    loss = []\n",
    "\n",
    "    for j in range(df.shape[0]): #iterating over all rows in the df\n",
    "        X = df[['internships', 'profile_score']].values[j].reshape(2,1)\n",
    "        y = df[['placed']].values[j][0]\n",
    "\n",
    "        y_hat, A1 = forward_propagation(X, parameters)\n",
    "        back_propogation(parameters, y, y_hat, A1, X)\n",
    "\n",
    "        loss.append(-y*np.log(y_hat) - (1-y)*np.log(1-y_hat)) # Loss function is LogLoss and Activation Function is Sigmoid\n",
    "\n",
    "    if(i%5==0):\n",
    "        print(f\"Epoch - {i}, Loss - {np.array(loss).mean()}\")\n",
    "\n",
    "print(\"Final Parameters: \", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dc07a-843f-498f-bcd0-939831c453b7",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6aec35-515f-4425-87ec-bae3404cd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f32ec0-135f-4da0-ab00-2b35c26b8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(2,)))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b689f60e-5c27-4a83-9c13-10c698f033da",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tensorflow.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70279d12-81d6-4670-9280-dafea03fe46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3fbb5d-3853-40fa-8004-ae978eba2430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.08305001, -0.79011786],\n",
       "        [-0.05051255,  0.9971217 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.4174615],\n",
       "        [ 1.3361219]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25cadb81-ecde-45e5-8eac-aa1e79e4f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([\n",
    "    np.array([[1,1],[1,1]]), np.array([0,0]), np.array([[1],[1]]), np.array([0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016316c4-1307-4c25-b22f-57a82b57f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 966us/step - loss: 0.9275\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.8900\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 647us/step - loss: 0.8722\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.8650\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.8369\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.8241\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.8067\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.7974\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.7903\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.7755\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.7608\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 644us/step - loss: 0.7466\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 645us/step - loss: 0.7429\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.7345\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.7243\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.7248\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.7137\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.7096\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.7015\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.6976\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.6984\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.6899\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 485us/step - loss: 0.6828\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.6806\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 535us/step - loss: 0.6736\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 591us/step - loss: 0.6716\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 638us/step - loss: 0.6760\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.6602\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.6548\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.6560\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.6547\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.6536\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.6522\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.6571\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.6576\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.6487\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.6478\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 593us/step - loss: 0.6511\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.6460\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.6480\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.6435\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.6447\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.6424\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 539us/step - loss: 0.6426\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.6410\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.6426\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.6427\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.6407\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.6399\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.6467\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.6432\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.6378\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 530us/step - loss: 0.6354\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 496us/step - loss: 0.6356\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.6352\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 544us/step - loss: 0.6348\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.6352\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.6323\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.6314\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 530us/step - loss: 0.6323\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.6299\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.6330\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.6283\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 542us/step - loss: 0.6273\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.6283\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.6285\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.6259\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.6314\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.6261\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.6267\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.6242\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 530us/step - loss: 0.6237\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.6233\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.6273\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 663us/step - loss: 0.6214\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.6201\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.6215\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 504us/step - loss: 0.6215\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 542us/step - loss: 0.6197\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.6222\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 505us/step - loss: 0.6184\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.6177\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.6153\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.6205\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 542us/step - loss: 0.6182\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 547us/step - loss: 0.6234\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.6152\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.6201\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.6115\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 528us/step - loss: 0.6132\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.6123\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.6126\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.6119\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.6124\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 509us/step - loss: 0.6074\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.6089\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 518us/step - loss: 0.6064\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.6103\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.6049\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 529us/step - loss: 0.6041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a00ca710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df[['internships', 'profile_score']].values, df['placed'], epochs=100, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cd990f-d0b0-4b3d-ac6e-149550c042fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5377929 ,  0.5377929 ],\n",
       "        [-0.22082202, -0.22082202]], dtype=float32),\n",
       " array([-1.126851, -1.126851], dtype=float32),\n",
       " array([[0.83794653],\n",
       "        [0.83794653]], dtype=float32),\n",
       " array([-0.3923642], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
